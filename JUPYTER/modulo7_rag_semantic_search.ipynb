{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b7b411",
   "metadata": {},
   "source": [
    "# Modulo 7 – Semantic Search & RAG semplice\n",
    "\n",
    "In questo notebook implementiamo una ricerca semantica \"artigianale\" e un mini-RAG:\n",
    "\n",
    "- Creazione di embedding con SentenceTransformers\n",
    "- Calcolo della similarità coseno\n",
    "- Recupero dei top-k documenti come contesto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d77931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer('./hf/all-MiniLM-L6-v2')  # percorso locale\n",
    "\n",
    "documenti = [\n",
    "    'La regressione lineare è un modello semplice ma potente.',\n",
    "    'Le reti neurali convoluzionali sono usate in computer vision.',\n",
    "    'Random Forest è un ensemble di alberi decisionali.',\n",
    "]\n",
    "\n",
    "doc_emb = model.encode(documenti)\n",
    "\n",
    "def cerca(query, top_k=2):\n",
    "    q_emb = model.encode([query])[0]\n",
    "    scores = []\n",
    "    for e in doc_emb:\n",
    "        sim = float(np.dot(q_emb, e) / ((np.linalg.norm(q_emb)+1e-9)*(np.linalg.norm(e)+1e-9)))\n",
    "        scores.append(sim)\n",
    "    idx = np.argsort(scores)[::-1][:top_k]\n",
    "    return [(documenti[i], scores[i]) for i in idx]\n",
    "\n",
    "risultati = cerca('Come funziona una Random Forest?')\n",
    "for testo, score in risultati:\n",
    "    print(f'{score:.3f} -> {testo}')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}